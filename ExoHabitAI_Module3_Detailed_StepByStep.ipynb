{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "955dd197",
   "metadata": {},
   "source": [
    "\n",
    "# ExoHabitAI ‚Äì Module 3: Machine Learning Dataset Preparation\n",
    "\n",
    "üìå **Goal of Module 3**  \n",
    "Convert the cleaned & engineered dataset from Module 2 into **ML-ready train/test datasets**\n",
    "without changing any scientific or logical assumptions.\n",
    "\n",
    "‚ö†Ô∏è **Important**  \n",
    "- Logic is **IDENTICAL** to the original implementation  \n",
    "- Code is only **restructured for readability & explanation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef995120",
   "metadata": {},
   "source": [
    "\n",
    "## 1Ô∏è‚É£ Imports\n",
    "\n",
    "These libraries are used for:\n",
    "- Data handling\n",
    "- Train/test splitting\n",
    "- Feature scaling\n",
    "- Feature selection\n",
    "- Saving ML artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4f11a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea7788",
   "metadata": {},
   "source": [
    "\n",
    "## 2Ô∏è‚É£ MLDatasetPreparator Class\n",
    "\n",
    "This class prepares datasets for machine learning by:\n",
    "- Identifying or creating a target variable\n",
    "- Selecting high-quality numerical features\n",
    "- Handling imbalance safely\n",
    "- Scaling features\n",
    "- Saving reusable ML artifacts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc9707f",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 `__init__()`\n",
    "\n",
    "Initializes:\n",
    "- Placeholders for train/test splits\n",
    "- RobustScaler (better for outliers)\n",
    "- Feature name tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a3eaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLDatasetPreparator:\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.feature_names = []\n",
    "        self.scaler = RobustScaler()\n",
    "        self.target_column = None\n",
    "    \n",
    "    def find_target_variable(self):\n",
    "        print(\"\\nLooking for target variable...\")\n",
    "\n",
    "        target_priority = [\n",
    "            'is_potentially_habitable',\n",
    "            'is_habitable',\n",
    "            'habitability_binary',\n",
    "            'habitability_class',\n",
    "            'habitability_tier',\n",
    "            'habitability_label',\n",
    "        ]\n",
    "\n",
    "        for target in target_priority:\n",
    "            if target in self.df.columns:\n",
    "                print(f\"‚úì Found target variable: '{target}'\")\n",
    "                self.target_column = target\n",
    "                return True\n",
    "\n",
    "        print(\"Checking for binary columns that could be targets...\")\n",
    "        binary_candidates = []\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype in ['int64', 'float64']:\n",
    "                unique_vals = self.df[col].dropna().unique()\n",
    "                if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1}):\n",
    "                    binary_candidates.append(col)\n",
    "\n",
    "        if binary_candidates:\n",
    "            for col in binary_candidates:\n",
    "                if 'habit' in col.lower() or 'class' in col.lower():\n",
    "                    self.target_column = col\n",
    "                    print(f\"‚úì Selected '{col}' as target variable\")\n",
    "                    return True\n",
    "            self.target_column = binary_candidates[0]\n",
    "            print(f\"‚úì Selected '{binary_candidates[0]}' as target variable\")\n",
    "            return True\n",
    "\n",
    "        if 'habitability_score' in self.df.columns:\n",
    "            print(\"‚úì Found 'habitability_score', will create binary target\")\n",
    "            self.target_column = 'habitability_score'\n",
    "            return True\n",
    "\n",
    "        print(\"‚ö† No suitable target variable found. Creating one...\")\n",
    "        return self.create_target_variable()\n",
    "\n",
    "    def create_target_variable(self):\n",
    "        print(\"Creating binary habitability target...\")\n",
    "\n",
    "        if 'in_habitable_zone' in self.df.columns:\n",
    "            self.df['is_habitable'] = self.df['in_habitable_zone']\n",
    "            self.target_column = 'is_habitable'\n",
    "            return True\n",
    "\n",
    "        elif all(col in self.df.columns for col in ['pl_eqt', 'pl_rade']):\n",
    "            temp_condition = (self.df['pl_eqt'] >= 250) & (self.df['pl_eqt'] <= 350)\n",
    "            size_condition = (self.df['pl_rade'] >= 0.8) & (self.df['pl_rade'] <= 1.5)\n",
    "            self.df['is_habitable'] = (temp_condition & size_condition).astype(int)\n",
    "            self.target_column = 'is_habitable'\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            print(\"‚ùå Not enough data to create target variable\")\n",
    "            return False\n",
    "\n",
    "    def prepare_target_variable(self):\n",
    "        print(f\"\\nPreparing target variable '{self.target_column}'...\")\n",
    "        y = self.df[self.target_column].copy()\n",
    "\n",
    "        if y.dtype in ['float64', 'int64']:\n",
    "            unique_vals = y.dropna().unique()\n",
    "            if len(unique_vals) == 2 and set(unique_vals) != {0, 1}:\n",
    "                y = y.replace({unique_vals[0]: 0, unique_vals[1]: 1})\n",
    "            elif 'score' in self.target_column.lower():\n",
    "                y = (y >= 50).astype(int)\n",
    "            else:\n",
    "                y = (y >= y.median()).astype(int)\n",
    "\n",
    "        elif y.dtype == 'object':\n",
    "            unique_cats = y.dropna().unique()\n",
    "            y = (y == unique_cats[0]).astype(int)\n",
    "\n",
    "        y.fillna(0, inplace=True)\n",
    "\n",
    "        self.df['target_binary'] = y.astype(int)\n",
    "        self.target_column = 'target_binary'\n",
    "\n",
    "        print(\"Target distribution:\")\n",
    "        print(self.df['target_binary'].value_counts())\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def select_features(self):\n",
    "        id_cols = ['pl_name', 'hostname', 'rowid', 'loc_rowid', 'index']\n",
    "        features_to_remove = [c for c in id_cols if c in self.df.columns]\n",
    "\n",
    "        if self.target_column in self.df.columns:\n",
    "            features_to_remove.append(self.target_column)\n",
    "\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        features = []\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            if col in features_to_remove:\n",
    "                continue\n",
    "            if self.df[col].isnull().mean() > 0.5:\n",
    "                continue\n",
    "            if self.df[col].nunique() <= 2:\n",
    "                continue\n",
    "\n",
    "            self.df[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            self.df[col].fillna(self.df[col].median(), inplace=True)\n",
    "            features.append(col)\n",
    "\n",
    "        if len(features) > 30:\n",
    "            features = self.df[features].var().sort_values(ascending=False).head(30).index.tolist()\n",
    "\n",
    "        self.feature_names = features\n",
    "        print(f\"Selected {len(features)} features\")\n",
    "        return features\n",
    " \n",
    "    def create_train_test_split(self, test_size=0.2, random_state=42):\n",
    "        X = self.df[self.feature_names]\n",
    "        y = self.df[self.target_column].astype(int)\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y\n",
    "        )\n",
    "\n",
    "        print(\"Train size:\", len(self.X_train))\n",
    "        print(\"Test size:\", len(self.X_test))\n",
    "\n",
    "    def scale_features(self):\n",
    "        self.scaler.fit(self.X_train)\n",
    "\n",
    "        self.X_train_scaled = pd.DataFrame(\n",
    "            self.scaler.transform(self.X_train),\n",
    "            columns=self.feature_names,\n",
    "            index=self.X_train.index\n",
    "        )\n",
    "\n",
    "        self.X_test_scaled = pd.DataFrame(\n",
    "            self.scaler.transform(self.X_test),\n",
    "            columns=self.feature_names,\n",
    "            index=self.X_test.index\n",
    "        )\n",
    "\n",
    "        joblib.dump(self.scaler, 'ml_scaler.pkl')\n",
    "\n",
    "    def save_datasets(self):\n",
    "        self.X_train_scaled.to_csv('X_train_scaled.csv', index=False)\n",
    "        self.X_test_scaled.to_csv('X_test_scaled.csv', index=False)\n",
    "        self.y_train.to_csv('y_train.csv', index=False)\n",
    "        self.y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "        pd.DataFrame({'feature': self.feature_names}).to_csv('feature_names.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd0e0e",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 `find_target_variable()`\n",
    "\n",
    "Automatically detects the best target column:\n",
    "- Prefers habitability labels from Module 2\n",
    "- Falls back to binary columns\n",
    "- Can trigger target creation if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad82def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_target_variable(self):\n",
    "        print(\"\\nLooking for target variable...\")\n",
    "\n",
    "        target_priority = [\n",
    "            'is_potentially_habitable',\n",
    "            'is_habitable',\n",
    "            'habitability_binary',\n",
    "            'habitability_class',\n",
    "            'habitability_tier',\n",
    "            'habitability_label',\n",
    "        ]\n",
    "\n",
    "        for target in target_priority:\n",
    "            if target in self.df.columns:\n",
    "                print(f\"‚úì Found target variable: '{target}'\")\n",
    "                self.target_column = target\n",
    "                return True\n",
    "\n",
    "        print(\"Checking for binary columns that could be targets...\")\n",
    "        binary_candidates = []\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype in ['int64', 'float64']:\n",
    "                unique_vals = self.df[col].dropna().unique()\n",
    "                if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1}):\n",
    "                    binary_candidates.append(col)\n",
    "\n",
    "        if binary_candidates:\n",
    "            for col in binary_candidates:\n",
    "                if 'habit' in col.lower() or 'class' in col.lower():\n",
    "                    self.target_column = col\n",
    "                    print(f\"‚úì Selected '{col}' as target variable\")\n",
    "                    return True\n",
    "            self.target_column = binary_candidates[0]\n",
    "            print(f\"‚úì Selected '{binary_candidates[0]}' as target variable\")\n",
    "            return True\n",
    "\n",
    "        if 'habitability_score' in self.df.columns:\n",
    "            print(\"‚úì Found 'habitability_score', will create binary target\")\n",
    "            self.target_column = 'habitability_score'\n",
    "            return True\n",
    "\n",
    "        print(\"‚ö† No suitable target variable found. Creating one...\")\n",
    "        return self.create_target_variable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12edec1d",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 `create_target_variable()`\n",
    "\n",
    "Creates a binary habitability label when none exists using:\n",
    "- Habitable zone flag OR\n",
    "- Temperature + radius heuristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "646f4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_target_variable(self):\n",
    "        print(\"Creating binary habitability target...\")\n",
    "\n",
    "        if 'in_habitable_zone' in self.df.columns:\n",
    "            self.df['is_habitable'] = self.df['in_habitable_zone']\n",
    "            self.target_column = 'is_habitable'\n",
    "            return True\n",
    "\n",
    "        elif all(col in self.df.columns for col in ['pl_eqt', 'pl_rade']):\n",
    "            temp_condition = (self.df['pl_eqt'] >= 250) & (self.df['pl_eqt'] <= 350)\n",
    "            size_condition = (self.df['pl_rade'] >= 0.8) & (self.df['pl_rade'] <= 1.5)\n",
    "            self.df['is_habitable'] = (temp_condition & size_condition).astype(int)\n",
    "            self.target_column = 'is_habitable'\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            print(\"‚ùå Not enough data to create target variable\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28701416",
   "metadata": {},
   "source": [
    "\n",
    "### 2.4 `prepare_target_variable()`\n",
    "\n",
    "Ensures:\n",
    "- Target is binary (0/1)\n",
    "- Handles categorical or continuous targets\n",
    "- Creates unified `target_binary`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "761d23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_target_variable(self):\n",
    "        print(f\"\\nPreparing target variable '{self.target_column}'...\")\n",
    "        y = self.df[self.target_column].copy()\n",
    "\n",
    "        if y.dtype in ['float64', 'int64']:\n",
    "            unique_vals = y.dropna().unique()\n",
    "            if len(unique_vals) == 2 and set(unique_vals) != {0, 1}:\n",
    "                y = y.replace({unique_vals[0]: 0, unique_vals[1]: 1})\n",
    "            elif 'score' in self.target_column.lower():\n",
    "                y = (y >= 50).astype(int)\n",
    "            else:\n",
    "                y = (y >= y.median()).astype(int)\n",
    "\n",
    "        elif y.dtype == 'object':\n",
    "            unique_cats = y.dropna().unique()\n",
    "            y = (y == unique_cats[0]).astype(int)\n",
    "\n",
    "        y.fillna(0, inplace=True)\n",
    "\n",
    "        self.df['target_binary'] = y.astype(int)\n",
    "        self.target_column = 'target_binary'\n",
    "\n",
    "        print(\"Target distribution:\")\n",
    "        print(self.df['target_binary'].value_counts())\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a7223",
   "metadata": {},
   "source": [
    "\n",
    "### 2.5 `select_features()`\n",
    "\n",
    "Selects **high-quality numerical features** by:\n",
    "- Removing identifiers\n",
    "- Removing targets\n",
    "- Dropping low-variance & high-missing columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b18acf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_features(self):\n",
    "        id_cols = ['pl_name', 'hostname', 'rowid', 'loc_rowid', 'index']\n",
    "        features_to_remove = [c for c in id_cols if c in self.df.columns]\n",
    "\n",
    "        if self.target_column in self.df.columns:\n",
    "            features_to_remove.append(self.target_column)\n",
    "\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        features = []\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            if col in features_to_remove:\n",
    "                continue\n",
    "            if self.df[col].isnull().mean() > 0.5:\n",
    "                continue\n",
    "            if self.df[col].nunique() <= 2:\n",
    "                continue\n",
    "\n",
    "            self.df[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            self.df[col].fillna(self.df[col].median(), inplace=True)\n",
    "            features.append(col)\n",
    "\n",
    "        if len(features) > 30:\n",
    "            features = self.df[features].var().sort_values(ascending=False).head(30).index.tolist()\n",
    "\n",
    "        self.feature_names = features\n",
    "        print(f\"Selected {len(features)} features\")\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775438d7",
   "metadata": {},
   "source": [
    "\n",
    "### 2.6 `create_train_test_split()`\n",
    "\n",
    "Creates **stratified** train/test split to preserve class balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "992a0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_train_test_split(self, test_size=0.2, random_state=42):\n",
    "        X = self.df[self.feature_names]\n",
    "        y = self.df[self.target_column].astype(int)\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y\n",
    "        )\n",
    "\n",
    "        print(\"Train size:\", len(self.X_train))\n",
    "        print(\"Test size:\", len(self.X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3aa10",
   "metadata": {},
   "source": [
    "\n",
    "### 2.7 `scale_features()`\n",
    "\n",
    "Applies **RobustScaler** to reduce the effect of outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6ce2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_features(self):\n",
    "        self.scaler.fit(self.X_train)\n",
    "\n",
    "        self.X_train_scaled = pd.DataFrame(\n",
    "            self.scaler.transform(self.X_train),\n",
    "            columns=self.feature_names,\n",
    "            index=self.X_train.index\n",
    "        )\n",
    "\n",
    "        self.X_test_scaled = pd.DataFrame(\n",
    "            self.scaler.transform(self.X_test),\n",
    "            columns=self.feature_names,\n",
    "            index=self.X_test.index\n",
    "        )\n",
    "\n",
    "        joblib.dump(self.scaler, 'ml_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a59de8b",
   "metadata": {},
   "source": [
    "\n",
    "### 2.8 `save_datasets()`\n",
    "\n",
    "Saves:\n",
    "- Scaled datasets\n",
    "- Raw datasets\n",
    "- Feature list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3d9fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_datasets(self):\n",
    "        self.X_train_scaled.to_csv('X_train_scaled.csv', index=False)\n",
    "        self.X_test_scaled.to_csv('X_test_scaled.csv', index=False)\n",
    "        self.y_train.to_csv('y_train.csv', index=False)\n",
    "        self.y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "        pd.DataFrame({'feature': self.feature_names}).to_csv('feature_names.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a96a0",
   "metadata": {},
   "source": [
    "\n",
    "## 3Ô∏è‚É£ Run Module 3 Pipeline\n",
    "\n",
    "This cell executes **all steps** in correct order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1108d547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for target variable...\n",
      "‚úì Found target variable: 'is_potentially_habitable'\n",
      "\n",
      "Preparing target variable 'is_potentially_habitable'...\n",
      "Target distribution:\n",
      "target_binary\n",
      "0    33156\n",
      "1     5963\n",
      "Name: count, dtype: int64\n",
      "Selected 30 features\n",
      "Train size: 31295\n",
      "Test size: 7824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prep = MLDatasetPreparator()\n",
    "\n",
    "for fname in ['exoplanets_cleaned_ready.csv', 'exoplanets_processed.csv', 'exoplanet.csv']:\n",
    "    if os.path.exists(fname):\n",
    "        prep.df = pd.read_csv(fname)\n",
    "        break\n",
    "\n",
    "prep.find_target_variable()\n",
    "prep.prepare_target_variable()\n",
    "prep.select_features()\n",
    "prep.create_train_test_split()\n",
    "prep.scale_features()\n",
    "prep.save_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12454770",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Module 3 Completed\n",
    "\n",
    "You now have:\n",
    "- ML-ready train/test datasets\n",
    "- Robust scaling applied\n",
    "- Clean feature selection\n",
    "\n",
    "‚û°Ô∏è **Next: Module 4 ‚Äì Model Training & Evaluation**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
