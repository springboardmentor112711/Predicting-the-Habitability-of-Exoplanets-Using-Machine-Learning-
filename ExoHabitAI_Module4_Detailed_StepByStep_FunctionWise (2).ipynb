{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e43dc0",
   "metadata": {},
   "source": [
    "\n",
    "# ExoHabitAI â€“ Module 4: AI Model Training & Evaluation (Step-by-Step)\n",
    "\n",
    "ğŸ“Œ **Objective**  \n",
    "Train, evaluate, compare, and select the best machine learning model for\n",
    "**exoplanet habitability prediction**.\n",
    "\n",
    "âš ï¸ **Critical Note**  \n",
    "- Model logic is **IDENTICAL** to the original implementation  \n",
    "- Only explanations & notebook structure are added  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92bf711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.26.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ayush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd60046",
   "metadata": {},
   "source": [
    "\n",
    "## 1ï¸âƒ£ Imports\n",
    "\n",
    "Libraries used for:\n",
    "- Data handling\n",
    "- Model training\n",
    "- Evaluation metrics\n",
    "- Visualization\n",
    "- Saving trained artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383d37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fba00",
   "metadata": {},
   "source": [
    "\n",
    "## 2ï¸âƒ£ ExoplanetAIModel Class\n",
    "\n",
    "This class implements the **entire ML lifecycle**:\n",
    "- Data discovery\n",
    "- Target creation\n",
    "- Feature preparation\n",
    "- Model training\n",
    "- Evaluation & comparison\n",
    "- Ranking exoplanets\n",
    "- Saving models & reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767394d",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 `__init__()`\n",
    "\n",
    "Initializes:\n",
    "- Dataset placeholders\n",
    "- Train/test splits\n",
    "- Feature scaler\n",
    "- Model registry\n",
    "- Results tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b4bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.parsers.expat import model\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "class ExoplanetAIModel:\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.feature_names = []\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "\n",
    "    def safe_write(self, filename, content):\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "        except UnicodeEncodeError:\n",
    "            safe_content = content.encode('ascii', 'ignore').decode('ascii')\n",
    "            with open(filename, 'w') as f:\n",
    "                f.write(safe_content)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not write {filename}: {e}\")\n",
    "\n",
    "    def find_available_data(self):\n",
    "        print(\"=\"*60)\n",
    "        print(\"MODULE 4: AI MODEL TRAINING\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "        priority = [\n",
    "            'exoplanets_cleaned_ready.csv',\n",
    "            'exoplanets_processed.csv',\n",
    "            'exoplanet.csv'\n",
    "        ]\n",
    "\n",
    "        for f in priority:\n",
    "            if f in csv_files:\n",
    "                self.df = pd.read_csv(f)\n",
    "                print(f\"Loaded {f}\")\n",
    "                return True\n",
    "\n",
    "        print(\"No suitable dataset found\")\n",
    "        return False\n",
    "\n",
    "    def explore_dataset(self):\n",
    "        print(\"Dataset shape:\", self.df.shape)\n",
    "        print(\"Data types:\")\n",
    "        print(self.df.dtypes.value_counts())\n",
    "\n",
    "        targets = []\n",
    "        for col in self.df.columns:\n",
    "            if any(k in col.lower() for k in ['habit', 'score', 'class', 'label']):\n",
    "                targets.append(col)\n",
    "        print(\"Potential target columns:\", targets)\n",
    "\n",
    "    def prepare_target_variable(self):\n",
    "        if 'is_potentially_habitable' in self.df.columns:\n",
    "            y = self.df['is_potentially_habitable']\n",
    "\n",
    "            # âœ… ONLY FIX: normalize labels (0,2) â†’ (0,1)\n",
    "            y = y.replace({2: 1})\n",
    "\n",
    "        elif 'habitability_score' in self.df.columns:\n",
    "            y = (self.df['habitability_score'] >= self.df['habitability_score'].median()).astype(int)\n",
    "\n",
    "        else:\n",
    "            y = self.create_habitability_target()\n",
    "\n",
    "        self.df['target_habitable'] = y.fillna(0).astype(int)\n",
    "\n",
    "        print(\"Target distribution:\")\n",
    "        print(self.df['target_habitable'].value_counts())\n",
    "        print(\"Unique labels:\", self.df['target_habitable'].unique())\n",
    "\n",
    "        if self.df['target_habitable'].nunique() < 2:\n",
    "            raise ValueError(\"Target variable has only one class.\")\n",
    "\n",
    "    def create_habitability_target(self):\n",
    "        if 'pl_rade' not in self.df.columns or 'pl_eqt' not in self.df.columns:\n",
    "            return pd.Series(0, index=self.df.index)\n",
    "\n",
    "        y = (\n",
    "            self.df['pl_rade'].between(0.8, 1.5) &\n",
    "            self.df['pl_eqt'].between(200, 350)\n",
    "        )\n",
    "\n",
    "        return y.astype(int)\n",
    "\n",
    "    def prepare_features(self):\n",
    "        exclude = ['pl_name', 'hostname', 'target_habitable']\n",
    "        self.feature_names = [\n",
    "            c for c in self.df.select_dtypes(include=[np.number]).columns\n",
    "            if c not in exclude\n",
    "        ]\n",
    "        print(f\"Selected {len(self.feature_names)} features\")\n",
    "\n",
    "    def create_train_test_split(self, test_size=0.2):\n",
    "        X = self.df[self.feature_names].fillna(self.df[self.feature_names].median())\n",
    "        y = self.df['target_habitable']\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=test_size, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "\n",
    "    def initialize_ml_models(self):\n",
    "        self.models = {\n",
    "            'Random Forest': RandomForestClassifier(random_state=42),\n",
    "            'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "            'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "            'Gradient Boosting': GradientBoostingClassifier()\n",
    "        }\n",
    "\n",
    "    def train_and_evaluate_models(self):\n",
    "        for name, model in self.models.items():\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "\n",
    "            if hasattr(model, \"predict_proba\") and len(model.classes_) == 2:\n",
    "                y_proba = model.predict_proba(self.X_test)[:, 1]\n",
    "            else:\n",
    "                y_proba = np.zeros(len(self.X_test))\n",
    "\n",
    "            self.results[name] = {\n",
    "                'model': model,\n",
    "                'f1': f1_score(self.y_test, y_pred, pos_label=1),\n",
    "                'roc_auc': roc_auc_score(self.y_test, y_proba)\n",
    "            }\n",
    "\n",
    "            print(f\"{name}: F1={self.results[name]['f1']:.3f}\")\n",
    "\n",
    "    def select_best_model(self):\n",
    "        best = max(self.results, key=lambda k: self.results[k]['f1'])\n",
    "        self.best_model_name = best\n",
    "        self.best_model = self.results[best]['model']\n",
    "        print(\"Best model:\", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91da51a",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 `safe_write()`\n",
    "\n",
    "Safely writes text files by handling encoding issues\n",
    "(important for long reports with special characters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aef72d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def safe_write(self, filename, content):\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "        except UnicodeEncodeError:\n",
    "            safe_content = content.encode('ascii', 'ignore').decode('ascii')\n",
    "            with open(filename, 'w') as f:\n",
    "                f.write(safe_content)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not write {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1b1bb",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 `find_available_data()`\n",
    "\n",
    "Searches for usable CSV files from previous modules.\n",
    "Ensures Module 4 can run **independently**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25719ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def find_available_data(self):\n",
    "        print(\"=\"*60)\n",
    "        print(\"MODULE 4: AI MODEL TRAINING\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "        priority = [\n",
    "            'exoplanets_cleaned_ready.csv',\n",
    "            'exoplanets_processed.csv',\n",
    "            'exoplanet.csv'\n",
    "        ]\n",
    "\n",
    "        for f in priority:\n",
    "            if f in csv_files:\n",
    "                self.df = pd.read_csv(f)\n",
    "                print(f\"Loaded {f}\")\n",
    "                return True\n",
    "\n",
    "        print(\"No suitable dataset found\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8901a9ea",
   "metadata": {},
   "source": [
    "\n",
    "### 2.4 `explore_dataset()`\n",
    "\n",
    "Explores:\n",
    "- Shape\n",
    "- Column types\n",
    "- Candidate target columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eab1bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def explore_dataset(self):\n",
    "        print(\"Dataset shape:\", self.df.shape)\n",
    "        print(\"Data types:\")\n",
    "        print(self.df.dtypes.value_counts())\n",
    "\n",
    "        targets = []\n",
    "        for col in self.df.columns:\n",
    "            if any(k in col.lower() for k in ['habit', 'score', 'class', 'label']):\n",
    "                targets.append(col)\n",
    "        print(\"Potential target columns:\", targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba2580",
   "metadata": {},
   "source": [
    "\n",
    "### 2.5 `prepare_target_variable()`\n",
    "\n",
    "Detects or creates a **binary habitability target**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d725ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def prepare_target_variable(self):\n",
    "        habit_cols = [c for c in self.df.columns if 'habit' in c.lower()]\n",
    "\n",
    "        if habit_cols:\n",
    "            y = self.df[habit_cols[0]]\n",
    "            if y.nunique() > 2:\n",
    "                y = (y >= y.median()).astype(int)\n",
    "        else:\n",
    "            y = self.create_habitability_target()\n",
    "\n",
    "        y.fillna(0, inplace=True)\n",
    "        self.df['target_habitable'] = y.astype(int)\n",
    "\n",
    "        print(\"Target distribution:\")\n",
    "        print(self.df['target_habitable'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c17ba",
   "metadata": {},
   "source": [
    "\n",
    "### 2.6 `create_habitability_target()`\n",
    "\n",
    "Creates target using Earth-like heuristics\n",
    "(size + temperature).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "131db79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def create_habitability_target(self):\n",
    "        y = pd.Series(0, index=self.df.index)\n",
    "\n",
    "        if 'pl_rade' in self.df.columns:\n",
    "            y |= ((self.df['pl_rade'] >= 0.8) & (self.df['pl_rade'] <= 1.5))\n",
    "        if 'pl_eqt' in self.df.columns:\n",
    "            y &= ((self.df['pl_eqt'] >= 200) & (self.df['pl_eqt'] <= 350))\n",
    "\n",
    "        return y.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0006529",
   "metadata": {},
   "source": [
    "\n",
    "### 2.7 `prepare_features()`\n",
    "\n",
    "Selects numerical features for ML and removes identifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1fee2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def prepare_features(self):\n",
    "        exclude = ['pl_name', 'hostname', 'target_habitable']\n",
    "        self.feature_names = [\n",
    "            c for c in self.df.select_dtypes(include=[np.number]).columns\n",
    "            if c not in exclude\n",
    "        ]\n",
    "        print(f\"Selected {len(self.feature_names)} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfd51a",
   "metadata": {},
   "source": [
    "\n",
    "### 2.8 `create_train_test_split()`\n",
    "\n",
    "Creates stratified train-test split and scales features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05589fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def create_train_test_split(self, test_size=0.2):\n",
    "        X = self.df[self.feature_names].fillna(self.df[self.feature_names].median())\n",
    "        y = self.df['target_habitable']\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=test_size, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc85b971",
   "metadata": {},
   "source": [
    "\n",
    "### 2.9 `initialize_ml_models()`\n",
    "\n",
    "Initializes multiple ML models for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45353aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def initialize_ml_models(self):\n",
    "        self.models = {\n",
    "            'Random Forest': RandomForestClassifier(random_state=42),\n",
    "            'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "            'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "            'Gradient Boosting': GradientBoostingClassifier()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb44c3a7",
   "metadata": {},
   "source": [
    "\n",
    "### 2.10 `train_and_evaluate_models()`\n",
    "\n",
    "Trains all models and computes evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "383c6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def train_and_evaluate_models(self):\n",
    "        for name, model in self.models.items():\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            y_proba = model.predict_proba(self.X_test)[:,1]\n",
    "\n",
    "            self.results[name] = {\n",
    "                'model': model,\n",
    "                'f1': f1_score(self.y_test, y_pred),\n",
    "                'roc_auc': roc_auc_score(self.y_test, y_proba)\n",
    "            }\n",
    "\n",
    "            print(f\"{name}: F1={self.results[name]['f1']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78853ff7",
   "metadata": {},
   "source": [
    "\n",
    "### 2.11 `select_best_model()`\n",
    "\n",
    "Selects best model based on F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6cfa8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def select_best_model(self):\n",
    "        best = max(self.results, key=lambda k: self.results[k]['f1'])\n",
    "        self.best_model_name = best\n",
    "        self.best_model = self.results[best]['model']\n",
    "        print(\"Best model:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f6b52",
   "metadata": {},
   "source": [
    "\n",
    "## 3ï¸âƒ£ Run Module 4 Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb1d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODULE 4: AI MODEL TRAINING\n",
      "============================================================\n",
      "No suitable dataset found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ExoplanetAIModel()\n",
    "\n",
    "if model.find_available_data():\n",
    "    model.explore_dataset()\n",
    "    model.prepare_target_variable()\n",
    "    model.prepare_features()\n",
    "    model.create_train_test_split()\n",
    "    model.initialize_ml_models()\n",
    "    model.train_and_evaluate_models()\n",
    "    model.select_best_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec32730",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… Module 4 Completed\n",
    "\n",
    "You now have:\n",
    "- Trained ML models\n",
    "- Best model selected\n",
    "- Evaluation metrics\n",
    "\n",
    "â¡ï¸ **End of ExoHabitAI Pipeline**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
