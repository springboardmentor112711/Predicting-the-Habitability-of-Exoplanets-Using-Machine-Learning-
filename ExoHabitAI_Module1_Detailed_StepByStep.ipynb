{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb40aa5",
   "metadata": {},
   "source": [
    "\n",
    "# ExoHabitAI ‚Äì Module 1: Data Collection & Management\n",
    "\n",
    "üìå **Objective**  \n",
    "Safely load raw NASA Exoplanet Archive data, standardize it, validate quality,\n",
    "and store it for downstream processing.\n",
    "\n",
    "‚ö†Ô∏è Logic is **identical** to the original implementation.\n",
    "Only the notebook structure is changed for explanation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed76e3",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b4b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import csv\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa7ca6",
   "metadata": {},
   "source": [
    "\n",
    "## 2Ô∏è‚É£ ExoplanetDataCollector Class\n",
    "\n",
    "Handles:\n",
    "- Irregular NASA CSV loading\n",
    "- Column standardization\n",
    "- Schema validation\n",
    "- Database & CSV storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8506fd5",
   "metadata": {},
   "source": [
    "### 2.1 `__init__()` ‚Äì Initialize Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297b7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ExoplanetDataCollector:\n",
    "    def __init__(self, db_path='exoplanet_data.db'):\n",
    "        self.db_path = db_path\n",
    "        self.data_source = \"Unknown\"\n",
    "\n",
    "    def load_nasa_csv_safe(self, filepath):\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                filepath,\n",
    "                comment='#',\n",
    "                low_memory=False\n",
    "            )\n",
    "\n",
    "            df.columns = [c.strip() for c in df.columns]\n",
    "            self.data_source = \"NASA Exoplanet Archive CSV\"\n",
    "            return df\n",
    "\n",
    "        except Exception:\n",
    "            return self.load_csv_manually(filepath)\n",
    "\n",
    "    def load_csv_manually(self, filepath):\n",
    "        data, headers = [], []\n",
    "\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "\n",
    "            for row in reader:\n",
    "                if any('pl_name' in str(c).lower() for c in row):\n",
    "                    headers = row\n",
    "                    break\n",
    "\n",
    "            for row in reader:\n",
    "                if len(row) < len(headers):\n",
    "                    row += [''] * (len(headers) - len(row))\n",
    "                data.append(row)\n",
    "\n",
    "        return pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    def load_local_data(self, filepath):\n",
    "        if not os.path.exists(filepath):\n",
    "            return None\n",
    "\n",
    "        df = self.load_nasa_csv_safe(filepath)\n",
    "\n",
    "        if df is not None and not df.empty:\n",
    "            df = self.standardize_column_names(df)\n",
    "            df = self.filter_for_required_columns(df)\n",
    "            return df\n",
    "\n",
    "        return None\n",
    "\n",
    "    def standardize_column_names(self, df):\n",
    "        df.columns = [\n",
    "            str(c).lower()\n",
    "            .replace(' ', '_')\n",
    "            .replace('[', '')\n",
    "            .replace(']', '')\n",
    "            for c in df.columns\n",
    "        ]\n",
    "        return df\n",
    "\n",
    "    def filter_for_required_columns(self, df):\n",
    "        required = [\n",
    "            'pl_name', 'hostname', 'pl_rade', 'pl_bmasse', 'pl_orbper',\n",
    "            'pl_orbsmax', 'pl_eqt', 'st_teff', 'st_rad', 'st_mass',\n",
    "            'sy_dist', 'disc_year', 'discoverymethod'\n",
    "        ]\n",
    "\n",
    "        for c in required:\n",
    "            if c not in df.columns:\n",
    "                df[c] = np.nan\n",
    "\n",
    "        return df\n",
    "\n",
    "    def validate_schema(self, df):\n",
    "        for c in ['pl_name', 'pl_rade', 'pl_bmasse']:\n",
    "            if c not in df.columns:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def clean_data(self, df):\n",
    "        df = df[df['pl_name'].notna()].copy()\n",
    "\n",
    "        numeric_cols = [\n",
    "            'pl_rade', 'pl_bmasse', 'pl_orbper', 'pl_orbsmax',\n",
    "            'pl_eqt', 'st_teff', 'st_rad', 'st_mass', 'sy_dist'\n",
    "        ]\n",
    "\n",
    "        for c in numeric_cols:\n",
    "            if c in df.columns:\n",
    "                df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "        df['pl_dens'] = df['pl_bmasse'] / (df['pl_rade'] ** 3)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def save_to_database(self, df):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        df.to_sql('exoplanets_raw', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "\n",
    "    def save_to_csv(self, df):\n",
    "        df.to_csv('exoplanets_processed.csv', index=False)\n",
    "        df.head(100).to_csv('exoplanets_sample.csv', index=False)\n",
    "\n",
    "    def get_data_summary(self, df):\n",
    "        print('Total planets:', len(df))\n",
    "        print('Columns:', len(df.columns))\n",
    "        print('Radius range:', df['pl_rade'].min(), '‚Üí', df['pl_rade'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d780b",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 `load_nasa_csv_safe()`\n",
    "\n",
    "Attempts to safely load NASA CSV files that may:\n",
    "- Contain metadata\n",
    "- Have inconsistent headers\n",
    "- Include commented lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90ccc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def load_nasa_csv_safe(self, filepath):\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            data_start_line = 0\n",
    "            for i, line in enumerate(lines):\n",
    "                if any(k in line.lower() for k in ['pl_name', 'hostname']):\n",
    "                    data_start_line = i\n",
    "                    break\n",
    "\n",
    "            if data_start_line == 0:\n",
    "                df = pd.read_csv(filepath, comment='#', low_memory=False)\n",
    "            else:\n",
    "                df = pd.read_csv(filepath, skiprows=data_start_line, low_memory=False)\n",
    "\n",
    "            df.columns = [c.strip() for c in df.columns]\n",
    "            self.data_source = \"NASA Exoplanet Archive CSV\"\n",
    "            return df\n",
    "        except:\n",
    "            return self.load_csv_manually(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f1689a",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 `load_csv_manually()`\n",
    "\n",
    "Fallback loader using Python's CSV reader when pandas fails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d61840c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_csv_manually(self, filepath):\n",
    "        data, headers = [], []\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                if any('pl_name' in str(c).lower() for c in row):\n",
    "                    headers = row\n",
    "                    break\n",
    "            for row in reader:\n",
    "                if len(row) < len(headers):\n",
    "                    row += [''] * (len(headers) - len(row))\n",
    "                data.append(row)\n",
    "        return pd.DataFrame(data, columns=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3d09d",
   "metadata": {},
   "source": [
    "\n",
    "### 2.4 `load_local_data()`\n",
    "\n",
    "Tries multiple strategies to load CSV from disk safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "938470aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_local_data(self, filepath):\n",
    "        if not os.path.exists(filepath):\n",
    "            return None\n",
    "        df = self.load_nasa_csv_safe(filepath)\n",
    "        if df is not None and not df.empty:\n",
    "            df = self.standardize_column_names(df)\n",
    "            df = self.filter_for_required_columns(df)\n",
    "            return df\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7665d9",
   "metadata": {},
   "source": [
    "\n",
    "### 2.5 `standardize_column_names()`\n",
    "\n",
    "Maps different NASA column names into a consistent internal schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2272925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column_names(self, df):\n",
    "        df.columns = [str(c).lower().replace(' ', '_').replace('[','').replace(']','') for c in df.columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72f6e7",
   "metadata": {},
   "source": [
    "\n",
    "### 2.6 `filter_for_required_columns()`\n",
    "\n",
    "Ensures core scientific features exist; fills missing ones with NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33046026",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def filter_for_required_columns(self, df):\n",
    "        required = ['pl_name','hostname','pl_rade','pl_bmasse','pl_orbper',\n",
    "                    'pl_orbsmax','pl_eqt','st_teff','st_rad','st_mass','sy_dist',\n",
    "                    'disc_year','discoverymethod']\n",
    "        for c in required:\n",
    "            if c not in df.columns:\n",
    "                df[c] = np.nan\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8f35c",
   "metadata": {},
   "source": [
    "\n",
    "### 2.7 `validate_schema()`\n",
    "\n",
    "Checks if minimum viable scientific data exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86487c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def validate_schema(self, df):\n",
    "        for c in ['pl_name','pl_rade','pl_bmasse']:\n",
    "            if c not in df.columns:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40286772",
   "metadata": {},
   "source": [
    "\n",
    "### 2.8 `clean_data()`\n",
    "\n",
    "Removes invalid rows, converts numerics, computes planet density.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7012ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def clean_data(self, df):\n",
    "        df = df[df['pl_name'].notna()].copy()\n",
    "        for c in ['pl_rade','pl_bmasse','pl_orbper','pl_orbsmax','pl_eqt','st_teff','st_rad','st_mass','sy_dist']:\n",
    "            if c in df.columns:\n",
    "                df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        df['pl_dens'] = df['pl_bmasse'] / (df['pl_rade'] ** 3)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa503336",
   "metadata": {},
   "source": [
    "\n",
    "### 2.9 `save_to_database()`\n",
    "\n",
    "Stores cleaned data into SQLite for reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6da439ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def save_to_database(self, df):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        df.to_sql('exoplanets_raw', conn, if_exists='replace', index=False)\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b0fbf2",
   "metadata": {},
   "source": [
    "\n",
    "### 2.10 `save_to_csv()`\n",
    "\n",
    "Exports cleaned data to CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc19bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def save_to_csv(self, df):\n",
    "        df.to_csv('exoplanets_processed.csv', index=False)\n",
    "        df.head(100).to_csv('exoplanets_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebf52f",
   "metadata": {},
   "source": [
    "\n",
    "### 2.11 `get_data_summary()`\n",
    "\n",
    "Prints human-readable statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc00c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_data_summary(self, df):\n",
    "        print('Total planets:', len(df))\n",
    "        print('Columns:', len(df.columns))\n",
    "        print('Radius range:', df['pl_rade'].min(), '‚Üí', df['pl_rade'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca026353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'clean_data', 'filter_for_required_columns', 'get_data_summary', 'load_csv_manually', 'load_local_data', 'load_nasa_csv_safe', 'save_to_csv', 'save_to_database', 'standardize_column_names', 'validate_schema']\n"
     ]
    }
   ],
   "source": [
    "print(dir(ExoplanetDataCollector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b173c",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Run Module 1 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11cc0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total planets: 39119\n",
      "Columns: 94\n",
      "Radius range: 0.27 ‚Üí 4282.98\n"
     ]
    }
   ],
   "source": [
    "collector = ExoplanetDataCollector()\n",
    "\n",
    "csv_path = \"A:\\Github\\Habitability_of_Exoplanets\\exoplanet.csv\"  \n",
    "\n",
    "df = collector.load_local_data(csv_path)\n",
    "\n",
    "if df is None or df.empty:\n",
    "    print(\"Failed to load CSV or CSV is empty\")\n",
    "else:\n",
    "    df = collector.clean_data(df)\n",
    "\n",
    "    if collector.validate_schema(df):\n",
    "        collector.save_to_database(df)\n",
    "        collector.save_to_csv(df)\n",
    "        collector.get_data_summary(df)\n",
    "    else:\n",
    "        print(\"Schema validation failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e55a0",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Module 1 Completed\n",
    "\n",
    "Outputs:\n",
    "- exoplanet_data.db\n",
    "- exoplanets_processed.csv\n",
    "- exoplanets_sample.csv\n",
    "\n",
    "‚û°Ô∏è Next: Module 2 ‚Äì Cleaning & Feature Engineering\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
